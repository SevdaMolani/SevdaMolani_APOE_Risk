{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the APOE dataframe to this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_21 = pd.read_csv(f'APOE_file_44908821.csv')\n",
    "df_21 = df_21[df_21['a_index'] == 1]\n",
    "df_21 = df_21[[\"s\",\"GT\"]]\n",
    "df_21 = df_21.rename(columns = {\"s\": \"person_id\" , \"GT\" : \"GT_rs7412\"})\n",
    "\n",
    "df_84 = pd.read_csv(f'APOE_file_44908684.csv')\n",
    "df_84 = df_84[df_84['a_index'] == 1]\n",
    "df_84 = df_84[[\"s\",\"GT\"]]\n",
    "df_84 = df_84.rename(columns = {\"s\": \"person_id\" , \"GT\" : \"GT_rs429358\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_APOE = pd.merge(df_21,df_84,on=\"person_id\",how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_APOE.loc[df_APOE[\"GT_rs7412\"] == \"0/0\", \"GT_rs7412\"] = 'CC'\n",
    "df_APOE.loc[df_APOE[\"GT_rs7412\"] == \"0/1\", \"GT_rs7412\"] = 'TC'\n",
    "df_APOE.loc[df_APOE[\"GT_rs7412\"] == \"1/1\", \"GT_rs7412\"] = 'TT'\n",
    "\n",
    "df_APOE.loc[df_APOE[\"GT_rs429358\"] == \"0/0\", \"GT_rs429358\"] = 'TT'\n",
    "df_APOE.loc[df_APOE[\"GT_rs429358\"] == \"0/1\", \"GT_rs429358\"] = 'CT'\n",
    "df_APOE.loc[df_APOE[\"GT_rs429358\"] == \"1/1\", \"GT_rs429358\"] = 'CC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def APOE_category(row):\n",
    "    if row[\"GT_rs7412\"] == \"CC\" and row[\"GT_rs429358\"] == \"CC\":\n",
    "        return \"e4e4\"\n",
    "    elif row[\"GT_rs7412\"] == \"CC\" and row[\"GT_rs429358\"] == \"CT\":\n",
    "        return \"e3e4\"\n",
    "    elif row[\"GT_rs7412\"] == \"TC\" and row[\"GT_rs429358\"] == \"CT\":\n",
    "        return \"e2e4\"\n",
    "    elif row[\"GT_rs7412\"] == \"CC\" and row[\"GT_rs429358\"] == \"TT\":\n",
    "        return \"e3e3\"\n",
    "    elif row[\"GT_rs7412\"] == \"TC\" and row[\"GT_rs429358\"] == \"TT\":\n",
    "        return \"e2e3\"\n",
    "    elif row[\"GT_rs7412\"] == \"TT\" and row[\"GT_rs429358\"] == \"TT\":\n",
    "        return \"e2e2\"\n",
    "    else:\n",
    "        return \"d\"\n",
    "\n",
    "df_APOE[\"APOE_group\"] = df_APOE.apply(APOE_category, axis=1)\n",
    "\n",
    "df_APOE = df_APOE[[\"person_id\",\"APOE_group\"]]\n",
    "\n",
    "df_APOE = df_APOE[df_APOE[\"APOE_group\"] != \"d\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patients and Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import os\n",
    "\n",
    "# This query represents dataset \"APOE_April2024\" for domain \"person\" and was generated for All of Us Controlled Tier Dataset v6\n",
    "dataset_49198409_person_sql = \"\"\"\n",
    "    SELECT\n",
    "        person.person_id,\n",
    "        p_gender_concept.concept_name as gender,\n",
    "        person.birth_datetime as date_of_birth,\n",
    "        p_race_concept.concept_name as race,\n",
    "        p_ethnicity_concept.concept_name as ethnicity,\n",
    "        p_sex_at_birth_concept.concept_name as sex_at_birth \n",
    "    FROM\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".person` person \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_gender_concept \n",
    "            ON person.gender_concept_id = p_gender_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_race_concept \n",
    "            ON person.race_concept_id = p_race_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_ethnicity_concept \n",
    "            ON person.ethnicity_concept_id = p_ethnicity_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_sex_at_birth_concept \n",
    "            ON person.sex_at_birth_concept_id = p_sex_at_birth_concept.concept_id  \n",
    "    WHERE\n",
    "        person.PERSON_ID IN (\n",
    "            SELECT\n",
    "                distinct person_id  \n",
    "            FROM\n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` cb_search_person  \n",
    "            WHERE\n",
    "                cb_search_person.person_id IN (\n",
    "                    SELECT\n",
    "                        person_id \n",
    "                    FROM\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` p \n",
    "                    WHERE\n",
    "                        has_whole_genome_variant = 1 \n",
    "                    UNION\n",
    "                    DISTINCT SELECT\n",
    "                        person_id \n",
    "                    FROM\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` p \n",
    "                    WHERE\n",
    "                        has_array_data = 1 \n",
    "                ) \n",
    "        )\"\"\"\n",
    "\n",
    "dataset_49198409_person_df = pandas.read_gbq(\n",
    "    dataset_49198409_person_sql,\n",
    "    dialect=\"standard\",\n",
    "    use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "    progress_bar_type=\"tqdm_notebook\") \n",
    "\n",
    "dataset_49198409_person_df = dataset_49198409_person_df.drop_duplicates(subset=['person_id'])\n",
    "dataset_49198409_person_df['date_of_birth'] = dataset_49198409_person_df['date_of_birth'].dt.date\n",
    "\n",
    "dataset_49198409_person_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gender_modify(row):\n",
    "    if row['gender'] == \"Male\" or row[\"sex_at_birth\"] == \"Male\":\n",
    "        return \"Male\"\n",
    "    else:\n",
    "        return \"Female\"\n",
    "\n",
    "# Apply the function to the DataFrame\n",
    "dataset_49198409_person_df['Gender_modified'] = dataset_49198409_person_df.apply(Gender_modify, axis=1)\n",
    "dataset_49198409_person_df = dataset_49198409_person_df.drop(columns=['gender']).drop(columns=['sex_at_birth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Race_modify(row):\n",
    "    if row['race'] == \"White\":\n",
    "        return \"White\"\n",
    "    elif row['race'] == \"Black or African American\":\n",
    "        return \"Black or African American\"\n",
    "    else:\n",
    "        return \"White\"\n",
    "\n",
    "# Apply the function to the DataFrame\n",
    "dataset_49198409_person_df['Race_modified'] = dataset_49198409_person_df.apply(Race_modify, axis=1)\n",
    "dataset_49198409_person_df = dataset_49198409_person_df.drop(columns=['race']).drop(columns=['ethnicity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_APOE_person = pd.merge(df_APOE,dataset_49198409_person_df,on=\"person_id\",how=\"inner\")\n",
    "df_APOE_person.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataframe = df_APOE_person\n",
    "\n",
    "# Replace 'test.csv' with THE NAME of the file you're going to store in the bucket (don't delete the quotation marks)\n",
    "destination_filename = 'APOE_file_Person.csv'\n",
    "\n",
    "# save dataframe in a csv file in the same workspace as the notebook\n",
    "my_dataframe.to_csv(destination_filename, index=False)\n",
    "\n",
    "# get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# copy csv file to the bucket\n",
    "args = [\"gsutil\", \"cp\", f\"./{destination_filename}\", f\"{my_bucket}/data/\"]\n",
    "output = subprocess.run(args, capture_output=True)\n",
    "\n",
    "# print output from gsutil\n",
    "output.stderr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drug dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import os\n",
    "\n",
    "# This query represents dataset \"APOE_April2024\" for domain \"drug\" and was generated for All of Us Controlled Tier Dataset v6\n",
    "dataset_49198409_drug_sql = \"\"\"\n",
    "    SELECT\n",
    "        d_exposure.person_id,\n",
    "        d_standard_concept.concept_name as standard_concept_name,\n",
    "        d_exposure.drug_exposure_start_datetime,\n",
    "        d_exposure.drug_exposure_end_datetime,\n",
    "        d_source_concept.concept_name as source_concept_name\n",
    "    FROM\n",
    "        ( SELECT\n",
    "            * \n",
    "        FROM\n",
    "            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".drug_exposure` d_exposure \n",
    "        WHERE\n",
    "            (\n",
    "                drug_concept_id IN (\n",
    "                    SELECT\n",
    "                        DISTINCT ca.descendant_id \n",
    "                    FROM\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria_ancestor` ca \n",
    "                    JOIN\n",
    "                        (\n",
    "                            SELECT\n",
    "                                DISTINCT c.concept_id       \n",
    "                            FROM\n",
    "                                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c       \n",
    "                            JOIN\n",
    "                                (\n",
    "                                    SELECT\n",
    "                                        CAST(cr.id as string) AS id             \n",
    "                                    FROM\n",
    "                                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr             \n",
    "                                    WHERE\n",
    "                                        concept_id IN (\n",
    "                                            21600438, 21600451, 21601664, 21601744, 21601782, 21601853\n",
    "                                        )             \n",
    "                                        AND full_text LIKE '%_rank1]%'       \n",
    "                                ) a \n",
    "                                    ON (\n",
    "                                        c.path LIKE CONCAT('%.',\n",
    "                                    a.id,\n",
    "                                    '.%') \n",
    "                                    OR c.path LIKE CONCAT('%.',\n",
    "                                    a.id) \n",
    "                                    OR c.path LIKE CONCAT(a.id,\n",
    "                                    '.%') \n",
    "                                    OR c.path = a.id) \n",
    "                                WHERE\n",
    "                                    is_standard = 1 \n",
    "                                    AND is_selectable = 1\n",
    "                                ) b \n",
    "                                    ON (\n",
    "                                        ca.ancestor_id = b.concept_id\n",
    "                                    )\n",
    "                            )\n",
    "                        )  \n",
    "                        AND (\n",
    "                            d_exposure.PERSON_ID IN (\n",
    "                                SELECT\n",
    "                                    distinct person_id  \n",
    "                            FROM\n",
    "                                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` cb_search_person  \n",
    "                            WHERE\n",
    "                                cb_search_person.person_id IN (\n",
    "                                    SELECT\n",
    "                                        person_id \n",
    "                                    FROM\n",
    "                                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` p \n",
    "                                    WHERE\n",
    "                                        has_whole_genome_variant = 1 \n",
    "                                    UNION\n",
    "                                    DISTINCT SELECT\n",
    "                                        person_id \n",
    "                                    FROM\n",
    "                                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` p \n",
    "                                    WHERE\n",
    "                                        has_array_data = 1 \n",
    "                                ) \n",
    "                        )\n",
    "                    )\n",
    "            ) d_exposure \n",
    "        LEFT JOIN\n",
    "            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` d_standard_concept \n",
    "                ON d_exposure.drug_concept_id = d_standard_concept.concept_id \n",
    "        LEFT JOIN\n",
    "            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` d_type \n",
    "                ON d_exposure.drug_type_concept_id = d_type.concept_id \n",
    "        LEFT JOIN\n",
    "            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` d_route \n",
    "                ON d_exposure.route_concept_id = d_route.concept_id \n",
    "        LEFT JOIN\n",
    "            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".visit_occurrence` v \n",
    "                ON d_exposure.visit_occurrence_id = v.visit_occurrence_id \n",
    "        LEFT JOIN\n",
    "            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` d_visit \n",
    "                ON v.visit_concept_id = d_visit.concept_id \n",
    "        LEFT JOIN\n",
    "            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` d_source_concept \n",
    "                ON d_exposure.drug_source_concept_id = d_source_concept.concept_id\"\"\"\n",
    "\n",
    "dataset_49198409_drug_df = pandas.read_gbq(\n",
    "    dataset_49198409_drug_sql,\n",
    "    dialect=\"standard\",\n",
    "    use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "    progress_bar_type=\"tqdm_notebook\")\n",
    "\n",
    "df_APOE_person_drug = pd.merge(df_APOE,dataset_49198409_drug_df,on=\"person_id\",how=\"inner\")\n",
    "df_APOE_person_drug.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def statin_use(row):\n",
    "    # Dictionaries to map statin drugs to their dosage and associated risk level\n",
    "    statin_mapping = {\n",
    "        'atorvastatin': {'10': 'Moderate', '20': 'Moderate', '40': 'High', '80': 'High', 'base': 'Moderate'},\n",
    "        'fluvastatin': {'20': 'Low', '40': 'Low', '80': 'Moderate', 'base': 'Low'},\n",
    "        'lovastatin': {'10': 'Low', '20': 'Low', '40': 'Moderate', '60': 'Moderate', '80': 'Moderate', 'base': 'Low'},\n",
    "        'pitavastatin': {'base': 'Moderate'},\n",
    "        'pravastatin': {'sodium 10': 'Low', 'sodium 20': 'Low', 'sodium 40': 'Moderate', 'sodium 80': 'Moderate', 'sodium 30': 'Moderate', 'base': 'Low'},\n",
    "        'rosuvastatin': {'5': 'Moderate', '10': 'Moderate', '20': 'High', '40': 'High', 'calcium 5': 'Moderate', 'calcium 10': 'Moderate', 'calcium 20': 'High', 'calcium 40': 'High', 'base': 'Moderate'},\n",
    "        'simvastatin': {'5': 'Low', '10': 'Low', '20': 'Moderate', '40': 'Moderate', '80': 'High', 'base': 'Low'}\n",
    "    }\n",
    "    \n",
    "    # Iterate through each drug and determine statin use\n",
    "    for drug, doses in statin_mapping.items():\n",
    "        if drug in row['standard_concept_name']:\n",
    "            for dose, level in doses.items():\n",
    "                if dose == 'base':  # Handle the base case (no specific dosage mentioned)\n",
    "                    if not re.search(r'\\d', row['standard_concept_name']):\n",
    "                        return level\n",
    "                elif f\"{drug} {dose}\" in row['standard_concept_name']:\n",
    "                    return level\n",
    "    return \"No\"  # Default case if no conditions are met\n",
    "\n",
    "# Apply the function to the DataFrame\n",
    "df_APOE_person_drug['statin_use'] = df_APOE_person_drug.apply(statin_use, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# List of hypertension medications\n",
    "Hypertension_meds = [\n",
    "    \"verapamil\", \"valsartan\", \"trandolapril\", \"telmisartan\", \"riociguat\", \"reserpine\", \"ramipril\", \"quinapril\", \"propranolol\",\n",
    "    \"prazosin\", \"polythiazide\", \"pindolol\", \"perindopril\", \"penbutolol\", \"olmesartan\", \"nisoldipine\", \"nifedipine\", \"nicardipine\",\n",
    "    \"nebivolol\", \"nadolol\", \"moexipril\", \"metoprolol\", \"methyldopa\", \"macitentan\", \"losartan\", \"lisinopril\", \"latanoprost\", \"labetalol\",\n",
    "    \"isradipine\", \"irbesartan\", \"indapamide\", \"hydrochlorothiazide\", \"hydralazine\", \"fosinopril\", \"felodipine\", \"eprosartan\", \"enalapril\",\n",
    "    \"dorzolamide\", \"diltiazem\", \"clonidine\", \"clevidipine\", \"chlorthalidone\", \"chlorothiazide\", \"celiprolol\", \"carvedilol\", \"carteolol\",\n",
    "    \"captopril\", \"candesartan\", \"bosentan\", \"bisoprolol\", \"betaxolol\", \"bendroflumethiazide\", \"benazepril\", \"azilsartan\", \"atenolol\",\n",
    "    \"amlodipine\", \"amiloride\", \"ambrisentan\", \"aliskiren\", \"acebutolol\", \"tadalafil\"\n",
    "]\n",
    "\n",
    "# Regular expression pattern for medications\n",
    "meds_pattern = '|'.join(Hypertension_meds)\n",
    "\n",
    "# Update the DataFrame\n",
    "df_APOE_person_drug['Hypertension_Med_Used'] = df_APOE_person_drug['standard_concept_name'].str.contains(meds_pattern).replace({True: 'Yes', False: 'No'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_APOE_person_drug['Aspirin_Used'] = df_APOE_person_drug['standard_concept_name'].str.contains(\"aspirin\").replace({True: 'Yes', False: 'No'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#statin_grouping\n",
    "statin_table = df_APOE_person_drug[df_APOE_person_drug[\"statin_use\"] != \"No\"]\n",
    "\n",
    "statin_table = statin_table.groupby(['person_id',\"statin_use\"]).agg({'drug_exposure_start_datetime': 'min', 'drug_exposure_end_datetime': 'max'}).reset_index()\n",
    "\n",
    "statin_table = statin_table.rename(columns={'drug_exposure_start_datetime': 'Min_statin_start', 'drug_exposure_end_datetime': 'Max_statin_end'})\n",
    "\n",
    "statin_table = statin_table.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hypertension_grouping\n",
    "Hypertension_table = df_APOE_person_drug[df_APOE_person_drug[\"Hypertension_Med_Used\"] != \"No\"]\n",
    "\n",
    "Hypertension_table = Hypertension_table.groupby(['person_id',\"Hypertension_Med_Used\"]).agg({'drug_exposure_start_datetime': 'min', 'drug_exposure_end_datetime': 'max'}).reset_index()\n",
    "Hypertension_table = Hypertension_table.rename(columns={'drug_exposure_start_datetime': 'Min_AntiHyper_start', 'drug_exposure_end_datetime': 'Max_Antihyper_end'})\n",
    "Hypertension_table = Hypertension_table.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aspirin_grouping\n",
    "Aspirin_table = df_APOE_person_drug[df_APOE_person_drug[\"Aspirin_Used\"] != \"No\"]\n",
    "\n",
    "Aspirin_table = Aspirin_table.groupby(['person_id',\"Aspirin_Used\"]).agg({'drug_exposure_start_datetime': 'min', 'drug_exposure_end_datetime': 'max'}).reset_index()\n",
    "Aspirin_table = Aspirin_table.rename(columns={'drug_exposure_start_datetime': 'Min_Aspirin_start', 'drug_exposure_end_datetime': 'Max_Aspirin_end'})\n",
    "Aspirin_table = Aspirin_table.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_APOE_demo_drug = pd.merge(df_APOE,statin_table,on=\"person_id\",how=\"left\")\n",
    "df_APOE_demo_drug = pd.merge(df_APOE_demo_drug,Hypertension_table,on=\"person_id\",how=\"left\")\n",
    "df_APOE_demo_drug = pd.merge(df_APOE_demo_drug,Aspirin_table,on=\"person_id\",how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_APOE_demo_drug['Min_statin_start'] = df_APOE_demo_drug['Min_statin_start'].dt.date\n",
    "df_APOE_demo_drug['Max_statin_end'] = df_APOE_demo_drug['Max_statin_end'].dt.date\n",
    "\n",
    "df_APOE_demo_drug['Min_AntiHyper_start'] = df_APOE_demo_drug['Min_AntiHyper_start'].dt.date\n",
    "df_APOE_demo_drug['Max_Antihyper_end'] = df_APOE_demo_drug['Max_Antihyper_end'].dt.date\n",
    "\n",
    "df_APOE_demo_drug['Min_Aspirin_start'] = df_APOE_demo_drug['Min_Aspirin_start'].dt.date\n",
    "df_APOE_demo_drug['Max_Aspirin_end'] = df_APOE_demo_drug['Max_Aspirin_end'].dt.date\n",
    "\n",
    "df_APOE_demo_drug.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataframe = df_APOE_demo_drug\n",
    "\n",
    "# Replace 'test.csv' with THE NAME of the file you're going to store in the bucket (don't delete the quotation marks)\n",
    "destination_filename = 'APOE_file_demo_drug.csv'\n",
    "\n",
    "# save dataframe in a csv file in the same workspace as the notebook\n",
    "my_dataframe.to_csv(destination_filename, index=False)\n",
    "\n",
    "# get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# copy csv file to the bucket\n",
    "args = [\"gsutil\", \"cp\", f\"./{destination_filename}\", f\"{my_bucket}/data/\"]\n",
    "output = subprocess.run(args, capture_output=True)\n",
    "\n",
    "# print output from gsutil\n",
    "output.stderr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import os\n",
    "\n",
    "# This query represents dataset \"APOE_April2024\" for domain \"measurement\" and was generated for All of Us Controlled Tier Dataset v6\n",
    "dataset_49198409_measurement_sql = \"\"\"\n",
    "    SELECT\n",
    "        measurement.person_id,\n",
    "        measurement.measurement_concept_id,\n",
    "        m_standard_concept.concept_name as standard_concept_name,\n",
    "        m_standard_concept.concept_code as standard_concept_code,\n",
    "        m_standard_concept.vocabulary_id as standard_vocabulary,\n",
    "        measurement.measurement_datetime,\n",
    "        measurement.value_as_number\n",
    "        \n",
    "    FROM\n",
    "        ( SELECT\n",
    "            * \n",
    "        FROM\n",
    "            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".measurement` measurement \n",
    "        WHERE\n",
    "            (\n",
    "                measurement_concept_id IN (\n",
    "                    SELECT\n",
    "                        DISTINCT c.concept_id \n",
    "                    FROM\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "                    JOIN\n",
    "                        (\n",
    "                            SELECT\n",
    "                                CAST(cr.id as string) AS id       \n",
    "                            FROM\n",
    "                                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr       \n",
    "                            WHERE\n",
    "                                concept_id IN (\n",
    "                                    3004249, 37053746, 40772572, 40772590\n",
    "                                )       \n",
    "                                AND full_text LIKE '%_rank1]%'      \n",
    "                        ) a \n",
    "                            ON (\n",
    "                                c.path LIKE CONCAT('%.',\n",
    "                            a.id,\n",
    "                            '.%') \n",
    "                            OR c.path LIKE CONCAT('%.',\n",
    "                            a.id) \n",
    "                            OR c.path LIKE CONCAT(a.id,\n",
    "                            '.%') \n",
    "                            OR c.path = a.id) \n",
    "                        WHERE\n",
    "                            is_standard = 1 \n",
    "                            AND is_selectable = 1\n",
    "                        )\n",
    "                )  \n",
    "                AND (\n",
    "                    measurement.PERSON_ID IN (\n",
    "                        SELECT\n",
    "                            distinct person_id  \n",
    "                        FROM\n",
    "                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` cb_search_person  \n",
    "                        WHERE\n",
    "                            cb_search_person.person_id IN (\n",
    "                                SELECT\n",
    "                                    person_id \n",
    "                                FROM\n",
    "                                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` p \n",
    "                                WHERE\n",
    "                                    has_whole_genome_variant = 1 \n",
    "                                UNION\n",
    "                                DISTINCT SELECT\n",
    "                                    person_id \n",
    "                                FROM\n",
    "                                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` p \n",
    "                                WHERE\n",
    "                                    has_array_data = 1 \n",
    "                            ) \n",
    "                    )\n",
    "                )\n",
    "        ) measurement \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` m_standard_concept \n",
    "            ON measurement.measurement_concept_id = m_standard_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` m_type \n",
    "            ON measurement.measurement_type_concept_id = m_type.concept_id \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` m_operator \n",
    "            ON measurement.operator_concept_id = m_operator.concept_id \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` m_value \n",
    "            ON measurement.value_as_concept_id = m_value.concept_id \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` m_unit \n",
    "            ON measurement.unit_concept_id = m_unit.concept_id \n",
    "    LEFT JOIn\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".visit_occurrence` v \n",
    "            ON measurement.visit_occurrence_id = v.visit_occurrence_id \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` m_visit \n",
    "            ON v.visit_concept_id = m_visit.concept_id \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` m_source_concept \n",
    "            ON measurement.measurement_source_concept_id = m_source_concept.concept_id\"\"\"\n",
    "\n",
    "dataset_49198409_measurement_df = pandas.read_gbq(\n",
    "    dataset_49198409_measurement_sql,\n",
    "    dialect=\"standard\",\n",
    "    use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "    progress_bar_type=\"tqdm_notebook\")\n",
    "\n",
    "df_APOE_person_drug_labs = pd.merge(df_APOE,dataset_49198409_measurement_df,on=\"person_id\",how=\"inner\")\n",
    "df_APOE_person_drug_labs['measurement_date'] = df_APOE_person_drug_labs['measurement_datetime'].dt.date\n",
    "\n",
    "df_APOE_person_drug_labs.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define conditions\n",
    "condition_cholesterol = (\n",
    "    df_APOE_person_drug_labs['standard_concept_name'].str.contains('Cholesterol \\[Mass/volume\\]', case=False) & \n",
    "    df_APOE_person_drug_labs['standard_concept_name'].str.contains('serum', case=False)\n",
    ")\n",
    "\n",
    "condition_hdl = (\n",
    "    df_APOE_person_drug_labs['standard_concept_name'].str.contains('HDL', case=False) &\n",
    "    df_APOE_person_drug_labs['standard_concept_name'].str.contains('\\[Mass/volume\\]', case=False) &\n",
    "    df_APOE_person_drug_labs['standard_concept_name'].str.contains('serum', case=False) &\n",
    "    ~df_APOE_person_drug_labs['standard_concept_name'].str.contains('non', case=False) &\n",
    "    ~df_APOE_person_drug_labs['standard_concept_name'].str.contains('ratio', case=False)\n",
    ")\n",
    "\n",
    "# Extract and combine Cholesterol and HDL values\n",
    "cholesterol_data = df_APOE_person_drug_labs.loc[condition_cholesterol, ['person_id', 'value_as_number', 'measurement_date']]\n",
    "cholesterol_data.columns = ['person_id', 'Total_Cholesterol', 'Total_Cholesterol_time']\n",
    "\n",
    "hdl_data = df_APOE_person_drug_labs.loc[condition_hdl, ['person_id', 'value_as_number', 'measurement_date']]\n",
    "hdl_data.columns = ['person_id', 'HDL', 'HDL_time']\n",
    "\n",
    "combined_df = pd.merge(cholesterol_data, hdl_data, on='person_id')\n",
    "\n",
    "# Filter rows where Total_Cholesterol_time equals HDL_time\n",
    "filtered_combined_df = combined_df[combined_df['Total_Cholesterol_time'] == combined_df['HDL_time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataframe = filtered_combined_df\n",
    "\n",
    "# Replace 'test.csv' with THE NAME of the file you're going to store in the bucket (don't delete the quotation marks)\n",
    "destination_filename = 'APOE_file_HDL_TotalChol.csv'\n",
    "\n",
    "# save dataframe in a csv file in the same workspace as the notebook\n",
    "my_dataframe.to_csv(destination_filename, index=False)\n",
    "\n",
    "# get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# copy csv file to the bucket\n",
    "args = [\"gsutil\", \"cp\", f\"./{destination_filename}\", f\"{my_bucket}/data/\"]\n",
    "output = subprocess.run(args, capture_output=True)\n",
    "\n",
    "# print output from gsutil\n",
    "output.stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and merge SBP values\n",
    "condition_SBP = df_APOE_person_drug_labs['standard_concept_name'].str.contains('Systolic blood pressure', case=False)\n",
    "SBP_data = df_APOE_person_drug_labs.loc[condition_SBP, [\"person_id\",'value_as_number', 'measurement_date']]\n",
    "SBP_data.columns = ['person_id','SBP', 'SBP_time']\n",
    "SBP_data = SBP_data.drop_duplicates()\n",
    "\n",
    "SBP_data = SBP_data[SBP_data[\"SBP\"].notnull()]\n",
    "SBP_data = SBP_data[SBP_data[\"SBP\"]>=20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the dataframes\n",
    "df_HDL_TotalChol = pd.read_csv(f'APOE_file_HDL_TotalChol.csv')\n",
    "df_HDL_TotalChol['Total_Cholesterol_time'] = pd.to_datetime(df_HDL_TotalChol['Total_Cholesterol_time'])\n",
    "\n",
    "SBP_filtered_combined_df = pd.merge(df_HDL_TotalChol, SBP_data, on=\"person_id\", how=\"inner\")\n",
    "SBP_filtered_combined_df['SBP_time'] = pd.to_datetime(SBP_filtered_combined_df['SBP_time'])\n",
    "\n",
    "# Calculate the time difference\n",
    "SBP_filtered_combined_df['time_difference'] = abs(SBP_filtered_combined_df['SBP_time'] - SBP_filtered_combined_df['Total_Cholesterol_time'])\n",
    "\n",
    "# Filter based on the time condition within 30 days\n",
    "# time_delta = pd.Timedelta(days=30)\n",
    "# SBP_filtered_combined_df = SBP_filtered_combined_df[\n",
    "#     (SBP_filtered_combined_df['SBP_time'] <= SBP_filtered_combined_df['Total_Cholesterol_time'] + time_delta) &\n",
    "#     (SBP_filtered_combined_df['SBP_time'] >= SBP_filtered_combined_df['Total_Cholesterol_time'] - time_delta)\n",
    "# ]\n",
    "\n",
    "# Sort by person_id and time_difference\n",
    "SBP_filtered_combined_df = SBP_filtered_combined_df.sort_values(by=['person_id', 'time_difference'])\n",
    "\n",
    "# Drop duplicates to keep only the closest SBP_time for each Total_Cholesterol_time\n",
    "SBP_filtered_combined_df = SBP_filtered_combined_df.drop_duplicates(subset=['person_id', 'Total_Cholesterol_time'], keep='first')\n",
    "\n",
    "# Drop the time_difference column as it is no longer needed\n",
    "SBP_filtered_combined_df = SBP_filtered_combined_df.drop(columns=['time_difference'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataframe = SBP_filtered_combined_df\n",
    "\n",
    "# Replace 'test.csv' with THE NAME of the file you're going to store in the bucket (don't delete the quotation marks)\n",
    "destination_filename = 'APOE_file_labs_SBP.csv'\n",
    "\n",
    "# save dataframe in a csv file in the same workspace as the notebook\n",
    "my_dataframe.to_csv(destination_filename, index=False)\n",
    "\n",
    "# get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# copy csv file to the bucket\n",
    "args = [\"gsutil\", \"cp\", f\"./{destination_filename}\", f\"{my_bucket}/data/\"]\n",
    "output = subprocess.run(args, capture_output=True)\n",
    "\n",
    "# print output from gsutil\n",
    "output.stderr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smoking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import os\n",
    "\n",
    "# This query represents dataset \"APOE_April2024\" for domain \"observation\" and was generated for All of Us Controlled Tier Dataset v6\n",
    "dataset_49198409_observation_sql = \"\"\"\n",
    "    SELECT\n",
    "        observation.person_id,\n",
    "        o_standard_concept.concept_name as standard_concept_name,\n",
    "        observation.observation_datetime,\n",
    "        o_value.concept_name as value_as_concept_name\n",
    "    FROM\n",
    "        ( SELECT\n",
    "            * \n",
    "        FROM\n",
    "            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".observation` observation \n",
    "        WHERE\n",
    "            (\n",
    "                observation_concept_id IN (\n",
    "                    4144271, 4144272, 4222303, 42528924, 4276526, 4298794, 43054909, 4310250, 762500\n",
    "                )\n",
    "            )  \n",
    "            AND (\n",
    "                observation.PERSON_ID IN (\n",
    "                    SELECT\n",
    "                        distinct person_id  \n",
    "                    FROM\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` cb_search_person  \n",
    "                    WHERE\n",
    "                        cb_search_person.person_id IN (\n",
    "                            SELECT\n",
    "                                person_id \n",
    "                            FROM\n",
    "                                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` p \n",
    "                            WHERE\n",
    "                                has_whole_genome_variant = 1 \n",
    "                            UNION\n",
    "                            DISTINCT SELECT\n",
    "                                person_id \n",
    "                            FROM\n",
    "                                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` p \n",
    "                            WHERE\n",
    "                                has_array_data = 1 \n",
    "                        ) \n",
    "                )\n",
    "            )\n",
    "    ) observation \n",
    "LEFT JOIN\n",
    "    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` o_standard_concept \n",
    "        ON observation.observation_concept_id = o_standard_concept.concept_id \n",
    "LEFT JOIN\n",
    "    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` o_type \n",
    "        ON observation.observation_type_concept_id = o_type.concept_id \n",
    "LEFT JOIN\n",
    "    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` o_value \n",
    "        ON observation.value_as_concept_id = o_value.concept_id \n",
    "LEFT JOIN\n",
    "    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` o_qualifier \n",
    "        ON observation.qualifier_concept_id = o_qualifier.concept_id \n",
    "LEFT JOIN\n",
    "    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` o_unit \n",
    "        ON observation.unit_concept_id = o_unit.concept_id \n",
    "LEFT JOIN\n",
    "    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".visit_occurrence` v \n",
    "        ON observation.visit_occurrence_id = v.visit_occurrence_id \n",
    "LEFT JOIN\n",
    "    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` o_visit \n",
    "        ON v.visit_concept_id = o_visit.concept_id \n",
    "LEFT JOIN\n",
    "    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` o_source_concept \n",
    "        ON observation.observation_source_concept_id = o_source_concept.concept_id\"\"\"\n",
    "\n",
    "dataset_49198409_observation_df = pandas.read_gbq(\n",
    "    dataset_49198409_observation_sql,\n",
    "    dialect=\"standard\",\n",
    "    use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "    progress_bar_type=\"tqdm_notebook\")\n",
    "\n",
    "df_APOE_person_smoking = pd.merge(df_APOE,dataset_49198409_observation_df,on=\"person_id\",how=\"inner\")\n",
    "df_APOE_person_smoking['observation_datetime'] = df_APOE_person_smoking['observation_datetime'].dt.date\n",
    "\n",
    "df_APOE_person_smoking.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define smoker and non-smoker categories\n",
    "smoker_keywords = [\n",
    "    'Cigarette smoker', 'Current every day smoker', 'Current some day smoker', \n",
    "    'Heavy tobacco smoker', 'Light tobacco smoker', 'Occasional tobacco smoker', 'Smoker', \n",
    "    'Smoker, current status unknown', 'Smokes tobacco daily', 'Chews tobacco', 'Cigar smoker', \n",
    "    'Pipe smoker', 'Snuff tobacco', 'Cigars',\"Yes\",'Pipe','Medications','Maybe'\n",
    "]\n",
    "\n",
    "non_smoker_keywords = [\n",
    "    'No matching concept', 'Never smoked tobacco', 'Never smoker', 'Non-smoker', 'Unknown if ever smoked', \n",
    "    'Unable to assess', 'Don\\'t know', 'None', 'No','Former smoker','Ex-smoker','Don\\'t know'\n",
    "]\n",
    "\n",
    "# Categorize the data\n",
    "df_APOE_person_smoking['smoker'] = df_APOE_person_smoking['value_as_concept_name'].apply(\n",
    "    lambda x: 'smoker' if x in smoker_keywords else 'non-smoker'\n",
    ")\n",
    "\n",
    "df_APOE_person_smoking = df_APOE_person_smoking.drop(columns=['standard_concept_name','value_as_concept_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataframe = df_APOE_person_smoking\n",
    "\n",
    "# Replace 'test.csv' with THE NAME of the file you're going to store in the bucket (don't delete the quotation marks)\n",
    "destination_filename = 'APOE_file_smoking.csv'\n",
    "\n",
    "# save dataframe in a csv file in the same workspace as the notebook\n",
    "my_dataframe.to_csv(destination_filename, index=False)\n",
    "\n",
    "# get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# copy csv file to the bucket\n",
    "args = [\"gsutil\", \"cp\", f\"./{destination_filename}\", f\"{my_bucket}/data/\"]\n",
    "output = subprocess.run(args, capture_output=True)\n",
    "\n",
    "# print output from gsutil\n",
    "output.stderr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import os\n",
    "\n",
    "# This query represents dataset \"APOE_April2024\" for domain \"condition\" and was generated for All of Us Controlled Tier Dataset v6\n",
    "dataset_87704195_condition_sql = \"\"\"\n",
    "    SELECT\n",
    "        c_occurrence.person_id,\n",
    "        c_occurrence.condition_concept_id,\n",
    "        c_standard_concept.concept_name as standard_concept_name,\n",
    "        c_standard_concept.concept_code as standard_concept_code,\n",
    "        c_standard_concept.vocabulary_id as standard_vocabulary,\n",
    "        c_occurrence.condition_start_datetime,\n",
    "        c_occurrence.condition_end_datetime,\n",
    "        c_occurrence.condition_type_concept_id,\n",
    "        c_type.concept_name as condition_type_concept_name,\n",
    "        c_occurrence.stop_reason,\n",
    "        c_occurrence.visit_occurrence_id,\n",
    "        visit.concept_name as visit_occurrence_concept_name,\n",
    "        c_occurrence.condition_source_value,\n",
    "        c_occurrence.condition_source_concept_id,\n",
    "        c_source_concept.concept_name as source_concept_name,\n",
    "        c_source_concept.concept_code as source_concept_code,\n",
    "        c_source_concept.vocabulary_id as source_vocabulary,\n",
    "        c_occurrence.condition_status_source_value,\n",
    "        c_occurrence.condition_status_concept_id,\n",
    "        c_status.concept_name as condition_status_concept_name \n",
    "    FROM\n",
    "        ( SELECT\n",
    "            * \n",
    "        FROM\n",
    "            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".condition_occurrence` c_occurrence \n",
    "        WHERE\n",
    "            (\n",
    "                condition_concept_id IN (SELECT\n",
    "                    DISTINCT c.concept_id \n",
    "                FROM\n",
    "                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "                JOIN\n",
    "                    (SELECT\n",
    "                        CAST(cr.id as string) AS id       \n",
    "                    FROM\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr       \n",
    "                    WHERE\n",
    "                        concept_id IN (201254, 201820, 201826, 4008576, 4193704, 443412)       \n",
    "                        AND full_text LIKE '%_rank1]%'      ) a \n",
    "                        ON (c.path LIKE CONCAT('%.', a.id, '.%') \n",
    "                        OR c.path LIKE CONCAT('%.', a.id) \n",
    "                        OR c.path LIKE CONCAT(a.id, '.%') \n",
    "                        OR c.path = a.id) \n",
    "                WHERE\n",
    "                    is_standard = 1 \n",
    "                    AND is_selectable = 1)\n",
    "            )  \n",
    "            AND (\n",
    "                c_occurrence.PERSON_ID IN (SELECT\n",
    "                    distinct person_id  \n",
    "                FROM\n",
    "                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` cb_search_person  \n",
    "                WHERE\n",
    "                    cb_search_person.person_id IN (SELECT\n",
    "                        person_id \n",
    "                    FROM\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` p \n",
    "                    WHERE\n",
    "                        has_whole_genome_variant = 1 \n",
    "                    UNION\n",
    "                    DISTINCT SELECT\n",
    "                        person_id \n",
    "                    FROM\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` p \n",
    "                    WHERE\n",
    "                        has_array_data = 1 ) )\n",
    "                )\n",
    "            ) c_occurrence \n",
    "        LEFT JOIN\n",
    "            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` c_standard_concept \n",
    "                ON c_occurrence.condition_concept_id = c_standard_concept.concept_id \n",
    "        LEFT JOIN\n",
    "            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` c_type \n",
    "                ON c_occurrence.condition_type_concept_id = c_type.concept_id \n",
    "        LEFT JOIN\n",
    "            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".visit_occurrence` v \n",
    "                ON c_occurrence.visit_occurrence_id = v.visit_occurrence_id \n",
    "        LEFT JOIN\n",
    "            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` visit \n",
    "                ON v.visit_concept_id = visit.concept_id \n",
    "        LEFT JOIN\n",
    "            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` c_source_concept \n",
    "                ON c_occurrence.condition_source_concept_id = c_source_concept.concept_id \n",
    "        LEFT JOIN\n",
    "            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` c_status \n",
    "                ON c_occurrence.condition_status_concept_id = c_status.concept_id\"\"\"\n",
    "\n",
    "dataset_87704195_condition_df = pandas.read_gbq(\n",
    "    dataset_87704195_condition_sql,\n",
    "    dialect=\"standard\",\n",
    "    use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "    progress_bar_type=\"tqdm_notebook\")\n",
    "\n",
    "df_APOE_person_Diabetes = pd.merge(df_APOE,dataset_87704195_condition_df,on=\"person_id\",how=\"inner\")\n",
    "df_APOE_person_Diabetes['condition_start_datetime'] = df_APOE_person_Diabetes['condition_start_datetime'].dt.date\n",
    "\n",
    "df_APOE_person_Diabetes.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_Diabetes = (\n",
    "    ~df_APOE_person_Diabetes['standard_concept_name'].str.lower().str.contains('during pregnancy', case=False) & \n",
    "    ~df_APOE_person_Diabetes['standard_concept_name'].str.lower().str.contains('neonatal', case=False) & \n",
    "    ~df_APOE_person_Diabetes['standard_concept_name'].str.lower().str.contains('gestational', case=False) &\n",
    "    ~df_APOE_person_Diabetes['standard_concept_name'].str.lower().str.contains('puerperium', case=False) &\n",
    "    ~df_APOE_person_Diabetes['standard_concept_name'].str.lower().str.contains('in pregnancy', case=False)\n",
    ")\n",
    "\n",
    "\n",
    "Diabetes_data = df_APOE_person_Diabetes.loc[condition_Diabetes, ['person_id', 'standard_concept_name', 'condition_start_datetime']]\n",
    "Diabetes_data.columns = ['person_id', 'standard_concept_name', 'condition_start_datetime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Diabetes_data = Diabetes_data.groupby(['person_id']).agg({'condition_start_datetime': 'min'}).reset_index()\n",
    "Diabetes_data = Diabetes_data.rename(columns={'condition_start_datetime': 'Diabetes_start_date'})\n",
    "Diabetes_data['Diabetes'] = \"1\"\n",
    "Diabetes_data = Diabetes_data.drop_duplicates()\n",
    "\n",
    "df_APOE_person_diabetes = pd.merge(df_APOE,Diabetes_data,on=\"person_id\",how=\"left\")\n",
    "df_APOE_person_diabetes['Diabetes'] = df_APOE_person_diabetes['Diabetes'].fillna(\"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataframe = df_APOE_person_diabetes\n",
    "\n",
    "# Replace 'test.csv' with THE NAME of the file you're going to store in the bucket (don't delete the quotation marks)\n",
    "destination_filename = 'APOE_file_Diabetes.csv'\n",
    "\n",
    "# save dataframe in a csv file in the same workspace as the notebook\n",
    "my_dataframe.to_csv(destination_filename, index=False)\n",
    "\n",
    "# get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# copy csv file to the bucket\n",
    "args = [\"gsutil\", \"cp\", f\"./{destination_filename}\", f\"{my_bucket}/data/\"]\n",
    "output = subprocess.run(args, capture_output=True)\n",
    "\n",
    "# print output from gsutil\n",
    "output.stderr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final edits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV files into DataFrames\n",
    "df_demo = pd.read_csv('APOE_file_Person.csv')\n",
    "df_demo = df_demo.drop_duplicates()\n",
    "print(df_demo.shape[0])\n",
    "print(df_demo['person_id'].nunique())\n",
    "\n",
    "df_labs = pd.read_csv('APOE_file_labs_SBP.csv')\n",
    "\n",
    "print(df_labs.shape[0])\n",
    "print(df_labs['person_id'].nunique())\n",
    "\n",
    "df_demo_labs = df_demo.merge(df_labs, on='person_id', how='inner')\n",
    "df_demo_labs = df_demo_labs.drop_duplicates()\n",
    "print(df_demo_labs.shape[0])\n",
    "print(df_demo_labs['person_id'].nunique())\n",
    "df_demo_labs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "df_smoking = pd.read_csv('APOE_file_smoking.csv').drop(columns=['APOE_group'])\n",
    "print(df_smoking.shape[0])\n",
    "print(df_smoking['person_id'].nunique())\n",
    "\n",
    "# Perform inner joins\n",
    "df_demo_lab_smoking = df_demo_labs.merge(df_smoking, on='person_id', how='left')\n",
    "\n",
    "df_demo_lab_smoking['Total_Cholesterol_time'] = pd.to_datetime(df_demo_lab_smoking['Total_Cholesterol_time'])\n",
    "df_demo_lab_smoking['observation_datetime'] = pd.to_datetime(df_demo_lab_smoking['observation_datetime'])\n",
    "\n",
    "# Calculate the time difference\n",
    "df_demo_lab_smoking['time_difference'] = abs(df_demo_lab_smoking['observation_datetime'] - df_demo_lab_smoking['Total_Cholesterol_time'])\n",
    "\n",
    "# Sort by person_id and time_difference\n",
    "df_demo_lab_smoking = df_demo_lab_smoking.sort_values(by=['person_id','Total_Cholesterol_time' ,'time_difference'])\n",
    "\n",
    "# Drop duplicates to keep only the closest SBP_time for each Total_Cholesterol_time\n",
    "df_demo_lab_smoking = df_demo_lab_smoking.drop_duplicates(subset=['person_id', 'Total_Cholesterol_time'], keep='first')\n",
    "print(df_demo_lab_smoking.shape[0])\n",
    "print(df_demo_lab_smoking['person_id'].nunique())\n",
    "\n",
    "df_demo_lab_smoking = df_demo_lab_smoking.drop(columns=[\"observation_datetime\",'time_difference'])\n",
    "\n",
    "df_demo_lab_smoking.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "\n",
    "df_drug = pd.read_csv('APOE_file_demo_drug.csv')\n",
    "df_drug= df_drug[['person_id', 'statin_use', 'Min_statin_start', 'Max_statin_end']]\n",
    "df_drug = df_drug.drop_duplicates()\n",
    "print(df_drug.shape[0])\n",
    "print(df_drug['person_id'].nunique())\n",
    "\n",
    "df_drug['Min_statin_start'] = pd.to_datetime(df_drug['Min_statin_start'])\n",
    "df_drug['Max_statin_end'] = pd.to_datetime(df_drug['Max_statin_end'])\n",
    "\n",
    "# Perform joins\n",
    "print(df_demo_lab_smoking.shape[0])\n",
    "print(df_demo_lab_smoking['person_id'].nunique())\n",
    "\n",
    "df_demo_lab_smoking_drugs = df_demo_lab_smoking.merge(df_drug, on='person_id', how='left')\n",
    "print(df_demo_lab_smoking_drugs.shape[0])\n",
    "print(df_demo_lab_smoking_drugs['person_id'].nunique())\n",
    "\n",
    "# Check if the statin start date is after the cholesterol date and replace the columns with null values\n",
    "condition = df_demo_lab_smoking_drugs['Min_statin_start'] >= df_demo_lab_smoking_drugs['Total_Cholesterol_time']\n",
    "df_demo_lab_smoking_drugs.loc[condition, ['statin_use', 'Min_statin_start', 'Max_statin_end']] = np.nan\n",
    "\n",
    "# Check if both statin start and end dates are less than the cholesterol date and replace the columns with null values\n",
    "condition = (df_demo_lab_smoking_drugs['Min_statin_start'] < df_demo_lab_smoking_drugs['Total_Cholesterol_time']) & (df_demo_lab_smoking_drugs['Max_statin_end'] < df_demo_lab_smoking_drugs['Total_Cholesterol_time'])\n",
    "df_demo_lab_smoking_drugs.loc[condition, ['statin_use', 'Min_statin_start', 'Max_statin_end']] = np.nan\n",
    "\n",
    "df_demo_lab_smoking_drugs = df_demo_lab_smoking_drugs.drop_duplicates()\n",
    "\n",
    "df_demo_lab_smoking_drugs = df_demo_lab_smoking_drugs[\n",
    "    ((df_demo_lab_smoking_drugs['Min_statin_start'] < df_demo_lab_smoking_drugs['Total_Cholesterol_time']) | \n",
    "     (df_demo_lab_smoking_drugs['Min_statin_start'].isnull())) &\n",
    "    ((df_demo_lab_smoking_drugs['Max_statin_end'] >= df_demo_lab_smoking_drugs['Total_Cholesterol_time']) | \n",
    "     (df_demo_lab_smoking_drugs['Max_statin_end'].isnull()))\n",
    "]\n",
    "\n",
    "print(df_demo_lab_smoking_drugs.shape[0])\n",
    "print(df_demo_lab_smoking_drugs['person_id'].nunique())\n",
    "\n",
    "# Define a function to map statin doses to numeric values\n",
    "def map_dose(dose):\n",
    "    dose_mapping = {'Low': 1, 'Moderate': 2, 'High': 3}\n",
    "    return dose_mapping.get(dose, 0)\n",
    "\n",
    "# Apply the dose mapping\n",
    "df_demo_lab_smoking_drugs['statin_dose_value'] = df_demo_lab_smoking_drugs['statin_use'].apply(map_dose)\n",
    "\n",
    "# Sort by person_id, Total_Cholesterol_time, and dose_value\n",
    "df_demo_lab_smoking_drugs = df_demo_lab_smoking_drugs.sort_values(by=['person_id', 'Total_Cholesterol_time', 'statin_dose_value'], ascending=[True, True, False])\n",
    "\n",
    "# Drop duplicates to keep only the highest dose statin for each Total_Cholesterol_time\n",
    "df_demo_lab_smoking_drugs = df_demo_lab_smoking_drugs.drop_duplicates(subset=['person_id', 'Total_Cholesterol_time'], keep='first')\n",
    "\n",
    "# Drop the unnecessary columns\n",
    "df_demo_lab_smoking_drugs = df_demo_lab_smoking_drugs.drop(columns=['Min_statin_start','Max_statin_end', 'statin_dose_value'])\n",
    "\n",
    "print(df_demo_lab_smoking_drugs.shape[0])\n",
    "print(df_demo_lab_smoking_drugs['person_id'].nunique())\n",
    "\n",
    "# Display the first few rows of the final DataFrame\n",
    "df_demo_lab_smoking_drugs.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "\n",
    "df_drug = pd.read_csv('APOE_file_demo_drug.csv')\n",
    "df_drug= df_drug[['person_id', 'Hypertension_Med_Used','Min_AntiHyper_start','Max_Antihyper_end']]\n",
    "df_drug = df_drug.drop_duplicates()\n",
    "print(df_drug.shape[0])\n",
    "print(df_drug['person_id'].nunique())\n",
    "\n",
    "df_drug['Min_AntiHyper_start'] = pd.to_datetime(df_drug['Min_AntiHyper_start'])\n",
    "df_drug['Max_Antihyper_end'] = pd.to_datetime(df_drug['Max_Antihyper_end'])\n",
    "\n",
    "# Perform joins\n",
    "print(df_demo_lab_smoking_drugs.shape[0])\n",
    "print(df_demo_lab_smoking_drugs['person_id'].nunique())\n",
    "\n",
    "df_demo_lab_smoking_drugs_AntiH = df_demo_lab_smoking_drugs.merge(df_drug, on='person_id', how='left')\n",
    "print(df_demo_lab_smoking_drugs_AntiH.shape[0])\n",
    "print(df_demo_lab_smoking_drugs_AntiH['person_id'].nunique())\n",
    "\n",
    "# Check if the statin start date is after the cholesterol date and replace the columns with null values\n",
    "condition = df_demo_lab_smoking_drugs_AntiH['Min_AntiHyper_start'] >= df_demo_lab_smoking_drugs_AntiH['Total_Cholesterol_time']\n",
    "df_demo_lab_smoking_drugs_AntiH.loc[condition, ['Hypertension_Med_Used','Min_AntiHyper_start','Max_Antihyper_end']] = np.nan\n",
    "\n",
    "# Check if both statin start and end dates are less than the cholesterol date and replace the columns with null values\n",
    "condition = (df_demo_lab_smoking_drugs_AntiH['Min_AntiHyper_start'] < df_demo_lab_smoking_drugs_AntiH['Total_Cholesterol_time']) & (df_demo_lab_smoking_drugs_AntiH['Max_Antihyper_end'] < df_demo_lab_smoking_drugs_AntiH['Total_Cholesterol_time'])\n",
    "df_demo_lab_smoking_drugs_AntiH.loc[condition, ['Hypertension_Med_Used','Min_AntiHyper_start','Max_Antihyper_end']] = np.nan\n",
    "\n",
    "df_demo_lab_smoking_drugs_AntiH = df_demo_lab_smoking_drugs_AntiH.drop_duplicates()\n",
    "\n",
    "df_demo_lab_smoking_drugs_AntiH = df_demo_lab_smoking_drugs_AntiH[\n",
    "    ((df_demo_lab_smoking_drugs_AntiH['Min_AntiHyper_start'] < df_demo_lab_smoking_drugs_AntiH['Total_Cholesterol_time']) | \n",
    "     (df_demo_lab_smoking_drugs_AntiH['Min_AntiHyper_start'].isnull())) &\n",
    "    ((df_demo_lab_smoking_drugs_AntiH['Max_Antihyper_end'] >= df_demo_lab_smoking_drugs_AntiH['Total_Cholesterol_time']) | \n",
    "     (df_demo_lab_smoking_drugs_AntiH['Max_Antihyper_end'].isnull()))\n",
    "]\n",
    "\n",
    "print(df_demo_lab_smoking_drugs_AntiH.shape[0])\n",
    "print(df_demo_lab_smoking_drugs_AntiH['person_id'].nunique())\n",
    "\n",
    "df_demo_lab_smoking_drugs_AntiH.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Diabetes = pd.read_csv('APOE_file_Diabetes.csv').drop(columns=['APOE_group'])\n",
    "print(df_Diabetes.shape[0])\n",
    "print(df_Diabetes['person_id'].nunique())\n",
    "\n",
    "# Specify the common column for joining, assuming it's 'PersonID'\n",
    "common_column = 'person_id'\n",
    "\n",
    "# Perform inner joins\n",
    "df_demo_lab_smoking_drugs_AntiH_Diab = df_demo_lab_smoking_drugs_AntiH.merge(df_Diabetes, on=common_column, how='left')\n",
    "\n",
    "print(df_demo_lab_smoking_drugs_AntiH_Diab.shape[0])\n",
    "print(df_demo_lab_smoking_drugs_AntiH_Diab['person_id'].nunique())\n",
    "\n",
    "df_demo_lab_smoking_drugs_AntiH_Diab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ensure the date columns are in datetime format\n",
    "df_demo_lab_smoking_drugs_AntiH_Diab['date_of_birth'] = pd.to_datetime(df_demo_lab_smoking_drugs_AntiH_Diab['date_of_birth'])\n",
    "df_demo_lab_smoking_drugs_AntiH_Diab['Total_Cholesterol_time'] = pd.to_datetime(df_demo_lab_smoking_drugs_AntiH_Diab['Total_Cholesterol_time'])\n",
    "\n",
    "# Calculate the age in years\n",
    "df_demo_lab_smoking_drugs_AntiH_Diab['Age'] = (df_demo_lab_smoking_drugs_AntiH_Diab['Total_Cholesterol_time'] - df_demo_lab_smoking_drugs_AntiH_Diab['date_of_birth']).dt.days // 365.25\n",
    "\n",
    "df_demo_lab_smoking_drugs_AntiH_Diab.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the date columns are in datetime format\n",
    "df_demo_lab_smoking_drugs_AntiH_Diab['Diabetes_start_date'] = pd.to_datetime(df_demo_lab_smoking_drugs_AntiH_Diab['Diabetes_start_date'])\n",
    "\n",
    "# Apply the condition row-wise\n",
    "df_demo_lab_smoking_drugs_AntiH_Diab['Diabetes_at_timeLab'] = df_demo_lab_smoking_drugs_AntiH_Diab.apply(\n",
    "    lambda row: '1' if row['Diabetes_start_date'] <= row['Total_Cholesterol_time'] else '0',\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(df_demo_lab_smoking_drugs_AntiH_Diab.shape[0])\n",
    "print(df_demo_lab_smoking_drugs_AntiH_Diab['person_id'].nunique())\n",
    "df_demo_lab_smoking_drugs_AntiH_Diab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo_lab_smoking_drugs_AntiH_Diab['Hypertension_Med_Used'] = df_demo_lab_smoking_drugs_AntiH_Diab['Hypertension_Med_Used'].apply(lambda x: \"1\" if x == 'Yes' else \"0\")\n",
    "df_demo_lab_smoking_drugs_AntiH_Diab['smoker'] = df_demo_lab_smoking_drugs_AntiH_Diab['smoker'].apply(lambda x: \"1\" if x == 'Yes' else \"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo_lab_smoking_drugs_AntiH_Diab = df_demo_lab_smoking_drugs_AntiH_Diab[df_demo_lab_smoking_drugs_AntiH_Diab[\"Total_Cholesterol\"]>1]\n",
    "df_demo_lab_smoking_drugs_AntiH_Diab = df_demo_lab_smoking_drugs_AntiH_Diab[df_demo_lab_smoking_drugs_AntiH_Diab[\"HDL\"]>1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataframe = df_demo_lab_smoking_drugs_AntiH_Diab\n",
    "\n",
    "# Replace 'test.csv' with THE NAME of the file you're going to store in the bucket (don't delete the quotation marks)\n",
    "destination_filename = 'APOE_file_Final_df.csv'\n",
    "\n",
    "# save dataframe in a csv file in the same workspace as the notebook\n",
    "my_dataframe.to_csv(destination_filename, index=False)\n",
    "\n",
    "# get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# copy csv file to the bucket\n",
    "args = [\"gsutil\", \"cp\", f\"./{destination_filename}\", f\"{my_bucket}/data/\"]\n",
    "output = subprocess.run(args, capture_output=True)\n",
    "\n",
    "# print output from gsutil\n",
    "output.stderr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cardiovascular event and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import os\n",
    "\n",
    "# This query represents dataset \"APOE_April2024\" for domain \"condition\" and was generated for All of Us Controlled Tier Dataset v6\n",
    "dataset_84056972_condition_sql = \"\"\"\n",
    "    SELECT\n",
    "        c_occurrence.person_id,\n",
    "        c_occurrence.condition_concept_id,\n",
    "        c_standard_concept.concept_name as standard_concept_name,\n",
    "        c_standard_concept.concept_code as standard_concept_code,\n",
    "        c_standard_concept.vocabulary_id as standard_vocabulary,\n",
    "        c_occurrence.condition_start_datetime,\n",
    "        c_occurrence.condition_end_datetime,\n",
    "        c_occurrence.condition_type_concept_id,\n",
    "        c_type.concept_name as condition_type_concept_name,\n",
    "        c_occurrence.stop_reason,\n",
    "        c_occurrence.visit_occurrence_id,\n",
    "        visit.concept_name as visit_occurrence_concept_name,\n",
    "        c_occurrence.condition_source_value,\n",
    "        c_occurrence.condition_source_concept_id,\n",
    "        c_source_concept.concept_name as source_concept_name,\n",
    "        c_source_concept.concept_code as source_concept_code,\n",
    "        c_source_concept.vocabulary_id as source_vocabulary,\n",
    "        c_occurrence.condition_status_source_value,\n",
    "        c_occurrence.condition_status_concept_id,\n",
    "        c_status.concept_name as condition_status_concept_name \n",
    "    FROM\n",
    "        ( SELECT\n",
    "            * \n",
    "        FROM\n",
    "            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".condition_occurrence` c_occurrence \n",
    "        WHERE\n",
    "            (\n",
    "                condition_concept_id IN (SELECT\n",
    "                    DISTINCT c.concept_id \n",
    "                FROM\n",
    "                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "                JOIN\n",
    "                    (SELECT\n",
    "                        CAST(cr.id as string) AS id       \n",
    "                    FROM\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr       \n",
    "                    WHERE\n",
    "                        concept_id IN (134057, 4023995, 4028244, 4028367)       \n",
    "                        AND full_text LIKE '%_rank1]%'      ) a \n",
    "                        ON (c.path LIKE CONCAT('%.', a.id, '.%') \n",
    "                        OR c.path LIKE CONCAT('%.', a.id) \n",
    "                        OR c.path LIKE CONCAT(a.id, '.%') \n",
    "                        OR c.path = a.id) \n",
    "                WHERE\n",
    "                    is_standard = 1 \n",
    "                    AND is_selectable = 1)\n",
    "            )  \n",
    "            AND (\n",
    "                c_occurrence.PERSON_ID IN (SELECT\n",
    "                    distinct person_id  \n",
    "                FROM\n",
    "                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` cb_search_person  \n",
    "                WHERE\n",
    "                    cb_search_person.person_id IN (SELECT\n",
    "                        person_id \n",
    "                    FROM\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` p \n",
    "                    WHERE\n",
    "                        has_whole_genome_variant = 1 \n",
    "                    UNION\n",
    "                    DISTINCT SELECT\n",
    "                        person_id \n",
    "                    FROM\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` p \n",
    "                    WHERE\n",
    "                        has_array_data = 1 ) )\n",
    "                )\n",
    "            ) c_occurrence \n",
    "        LEFT JOIN\n",
    "            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` c_standard_concept \n",
    "                ON c_occurrence.condition_concept_id = c_standard_concept.concept_id \n",
    "        LEFT JOIN\n",
    "            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` c_type \n",
    "                ON c_occurrence.condition_type_concept_id = c_type.concept_id \n",
    "        LEFT JOIN\n",
    "            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".visit_occurrence` v \n",
    "                ON c_occurrence.visit_occurrence_id = v.visit_occurrence_id \n",
    "        LEFT JOIN\n",
    "            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` visit \n",
    "                ON v.visit_concept_id = visit.concept_id \n",
    "        LEFT JOIN\n",
    "            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` c_source_concept \n",
    "                ON c_occurrence.condition_source_concept_id = c_source_concept.concept_id \n",
    "        LEFT JOIN\n",
    "            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` c_status \n",
    "                ON c_occurrence.condition_status_concept_id = c_status.concept_id\"\"\"\n",
    "\n",
    "dataset_84056972_condition_df = pandas.read_gbq(\n",
    "    dataset_84056972_condition_sql,\n",
    "    dialect=\"standard\",\n",
    "    use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "    progress_bar_type=\"tqdm_notebook\")\n",
    "\n",
    "df_APOE_person_CVD = pd.merge(df_APOE,dataset_84056972_condition_df,on=\"person_id\",how=\"inner\")\n",
    "df_APOE_person_CVD['condition_start_datetime'] = df_APOE_person_CVD['condition_start_datetime'].dt.date\n",
    "\n",
    "df_APOE_person_CVD.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_APOE_person_CVD = df_APOE_person_CVD[['person_id', 'standard_concept_name', 'condition_start_datetime']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_APOE_person_CVD = df_APOE_person_CVD.groupby(['person_id']).agg({'condition_start_datetime': 'min'}).reset_index()\n",
    "df_APOE_person_CVD = df_APOE_person_CVD.rename(columns={'condition_start_datetime': 'CVD_start_date'})\n",
    "df_APOE_person_CVD['CVD'] = \"1\"\n",
    "df_APOE_person_CVD = df_APOE_person_CVD.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_APOE_person_CVD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_APOE_person_CVD = pd.merge(df_APOE,df_APOE_person_CVD,on=\"person_id\",how=\"left\")\n",
    "df_APOE_person_CVD['CVD'] = df_APOE_person_CVD['CVD'].fillna(\"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_APOE_person_CVD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('APOE_file_Final_df.csv').drop(columns=['APOE_group'])\n",
    "df['Total_Cholesterol_time'] = pd.to_datetime(df['Total_Cholesterol_time'])\n",
    "# Specify the common column for joining, assuming it's 'PersonID'\n",
    "common_column = 'person_id'\n",
    "\n",
    "# Perform inner joins\n",
    "df_CVD = df.merge(df_APOE_person_CVD, on=common_column, how='left')\n",
    "\n",
    "print(df_CVD.shape[0])\n",
    "print(df_CVD['person_id'].nunique())\n",
    "\n",
    "df_CVD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the date columns are in datetime format\n",
    "df_CVD['CVD_start_date'] = pd.to_datetime(df_CVD['CVD_start_date'])\n",
    "\n",
    "# Apply the condition row-wise\n",
    "df_CVD['CVD_at_timeLab'] = df_CVD.apply(\n",
    "    lambda row: '1' if row['CVD_start_date'] >= row['Total_Cholesterol_time'] else '0',\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(df_CVD.shape[0])\n",
    "print(df_CVD['person_id'].nunique())\n",
    "df_CVD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataframe = df_CVD\n",
    "\n",
    "# Replace 'test.csv' with THE NAME of the file you're going to store in the bucket (don't delete the quotation marks)\n",
    "destination_filename = 'APOE_file_Final_df_CVD.csv'\n",
    "\n",
    "# save dataframe in a csv file in the same workspace as the notebook\n",
    "my_dataframe.to_csv(destination_filename, index=False)\n",
    "\n",
    "# get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# copy csv file to the bucket\n",
    "args = [\"gsutil\", \"cp\", f\"./{destination_filename}\", f\"{my_bucket}/data/\"]\n",
    "output = subprocess.run(args, capture_output=True)\n",
    "\n",
    "# print output from gsutil\n",
    "output.stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
